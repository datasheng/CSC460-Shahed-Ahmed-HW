{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## # Introduction\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n",
    "<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n",
    "<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n",
    "<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n",
    "<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shahed/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this cell to begin your analysis, and add as many as you would like!\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "3"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fetch the Peter Pan book\n",
    "r = requests.get('https://www.gutenberg.org/files/16/16-h/16-h.htm')\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "# Extract the text\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "3"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Tokenize text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Convert all tokens to lowercase\n",
    "words = [word.lower() for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "3"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load English stopwords\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "# Remove stopwords\n",
    "words_ns = [word for word in words if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('peter', 409), ('wendy', 362), ('said', 358), ('would', 217), ('one', 212), ('hook', 174), ('could', 142), ('cried', 136), ('john', 133), ('time', 126)]\n"
     ]
    }
   ],
   "source": [
    "# Count words\n",
    "count = Counter(words_ns)\n",
    "\n",
    "# Get top 10 most common words\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "# See the top ten\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "3"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "protagonists = [\"peter\", \"wendy\", \"hook\", \"john\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
